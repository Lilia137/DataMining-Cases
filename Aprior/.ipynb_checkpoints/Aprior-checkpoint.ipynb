{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b2d806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b8fb12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 生成1项集\n",
    "# 2. 生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81f13af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_C1(data_set):\n",
    "    C1 = set()\n",
    "    for t in data_set:\n",
    "        for item in t:\n",
    "            item_set = frozenset([item])\n",
    "            C1.add(item_set)\n",
    "    return C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "420429d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_apriori(Ck_item, Lksub1):\n",
    "    for item in Ck_item:\n",
    "        sub_Ck = Ck_item - frozenset([item])\n",
    "        if sub_Ck not in Lksub1:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "945aeb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Ck(Lksub1, k):\n",
    "    Ck = set()\n",
    "    len_Lksub1 = len(Lksub1)\n",
    "    list_Lksub1 = list(Lksub1)\n",
    "    for i in range(len_Lksub1):\n",
    "        for j in range(1, len_Lksub1):\n",
    "            l1 = list(list_Lksub1[i])\n",
    "            l2 = list(list_Lksub1[j])\n",
    "            l1.sort()\n",
    "            l2.sort()\n",
    "            if l1[0:k-2] == l2[0:k-2]:\n",
    "                Ck_item = list_Lksub1[i] | list_Lksub1[j]\n",
    "                # pruning\n",
    "                if is_apriori(Ck_item, Lksub1):\n",
    "                    Ck.add(Ck_item)\n",
    "    return Ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "116534e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Lk_by_Ck(data_set, Ck, min_support, support_data):\n",
    "    Lk = set()\n",
    "    item_count = {}\n",
    "    for t in data_set:\n",
    "        for item in Ck:\n",
    "            if item.issubset(t):\n",
    "                if item not in item_count:\n",
    "                    item_count[item] = 1\n",
    "                else:\n",
    "                    item_count[item] += 1\n",
    "    t_num = float(len(data_set))\n",
    "    for item in item_count:\n",
    "        if (item_count[item] / t_num) >= min_support:\n",
    "            Lk.add(item)\n",
    "            support_data[item] = item_count[item] / t_num\n",
    "    return Lk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4fb90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成频繁项集\n",
    "def generate_L(data_set, k, min_support):\n",
    "    support_data = {}\n",
    "    C1 = create_C1(data_set)\n",
    "    L1 = generate_Lk_by_Ck(data_set, C1, min_support, support_data)\n",
    "    Lksub1 = L1.copy()\n",
    "    L = []\n",
    "    L.append(Lksub1)\n",
    "    for i in range(2, k+1):\n",
    "        Ci = create_Ck(Lksub1, i)\n",
    "        Li = generate_Lk_by_Ck(data_set, Ci, min_support, support_data)\n",
    "        Lksub1 = Li.copy()\n",
    "        L.append(Lksub1)\n",
    "    return L, support_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7edcd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成关联规则\n",
    "def generate_big_rules(L, support_data, min_conf):\n",
    "    big_rule_list = []\n",
    "    sub_set_list = []\n",
    "    for i in range(0, len(L)):\n",
    "        for freq_set in L[i]:\n",
    "            for sub_set in sub_set_list:\n",
    "                if sub_set.issubset(freq_set):\n",
    "                    conf = support_data[freq_set] / support_data[freq_set - sub_set]\n",
    "                    big_rule = (freq_set - sub_set, sub_set, conf)\n",
    "                    if conf >= min_conf and big_rule not in big_rule_list:\n",
    "                        # print freq_set-sub_set, \" => \", sub_set, \"conf: \", conf\n",
    "                        big_rule_list.append(big_rule)\n",
    "            sub_set_list.append(freq_set)\n",
    "    return big_rule_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42288bc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'frozenset' object has no attribute 'remove'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-286168ac5224>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# 生成频繁项集\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msupport_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_L\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_support\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# 生成关联规则\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-d2ea7b3b7e95>\u001b[0m in \u001b[0;36mgenerate_L\u001b[1;34m(data_set, k, min_support)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLksub1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mCi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_Ck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLksub1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mLi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_Lk_by_Ck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_support\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msupport_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mLksub1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-79d817e2a2a3>\u001b[0m in \u001b[0;36mcreate_Ck\u001b[1;34m(Lksub1, k)\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mCk_item\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist_Lksub1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mlist_Lksub1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;31m# pruning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mis_apriori\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCk_item\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLksub1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m                     \u001b[0mCk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCk_item\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mCk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-702a075d78a6>\u001b[0m in \u001b[0;36mis_apriori\u001b[1;34m(Ck_item, Lksub1)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mCk_item\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#         sub_Ck = Ck_item - frozenset([item])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0msub_Ck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCk_item\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msub_Ck\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mLksub1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'frozenset' object has no attribute 'remove'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 获取并处理数据集，去除空值\n",
    "    data = pd.read_csv(\"goods2.csv\",header = None)\n",
    "    data = np.array(data)\n",
    "    data_set = [[i for i in row if not pd.isna(i)] for row in data]\n",
    "    \n",
    "    # 生成频繁项集\n",
    "    L, support_data = generate_L(data_set, k=3, min_support=0.5)\n",
    "    \n",
    "    # 生成关联规则\n",
    "    big_rules_list = generate_big_rules(L, support_data, min_conf=0.7)\n",
    "    \n",
    "    for Lk in L:\n",
    "        print(\"=\"*50)\n",
    "        print(\"frequent \" + str(len(list(Lk)[0])) + \"-itemsets\\t\\tsupport\")\n",
    "        print(\"=\"*50)\n",
    "        for freq_set in Lk:\n",
    "            print(freq_set, support_data[freq_set])\n",
    "    print (\"Big Rules\")\n",
    "    for item in big_rules_list:\n",
    "        print(item[0], \"=>\", item[1], \"conf: \", item[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cfd52e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
